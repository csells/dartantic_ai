---
title: Streaming Output
---

# Streaming Output

Watch your AI think in real-time. It's like watching paint dry, but fascinating.

## Basic Streaming

```dart
final agent = Agent('openai');

// Like watching a typist with 200 WPM
await for (final chunk in agent.sendStream('Tell me your best joke')) {
  stdout.write(chunk.output); 
}
// "Why don't scientists trust atoms?"
// (dramatic pause as it streams...)
// "Because they make up everything!"
```

## With Tools

```dart
// Tool calls stream alongside text
await for (final chunk in agent.sendStream(
  'Weather in NYC?',
  tools: [weatherTool],
)) {
  stdout.write(chunk.output);
  // Tool results integrated into stream
}
```

## With Typed Output

```dart
// Stream structured JSON
await for (final chunk in agent.sendStream(
  'List 3 facts',
  outputSchema: factsSchema,
)) {
  stdout.write(chunk.output); // Streams JSON chunks
}
```

## Error Handling

```dart
try {
  await for (final chunk in agent.sendStream('Hello')) {
    stdout.write(chunk.output);
  }
} catch (e) {
  print('Stream error: $e');
}
```

## Usage Tracking

```dart
var usage = const LanguageModelUsage();

await for (final chunk in agent.sendStream('Story time')) {
  stdout.write(chunk.output);
  if (chunk.usage.totalTokens != null) {
    usage = chunk.usage; // Final chunk contains usage
  }
}

print('\nTokens used: ${usage.totalTokens}');
```

## Provider Support

All providers support streaming:
- OpenAI, Anthropic, Google
- Mistral, Cohere, Ollama

## Examples

- [Chat with streaming](https://github.com/csells/darantic_ai/blob/main/packages/dartantic_ai/example/bin/chat.dart)
- [Multi-turn streaming](https://github.com/csells/darantic_ai/blob/main/packages/dartantic_ai/example/bin/multi_turn_chat.dart)
- [Agent with streaming](https://github.com/csells/darantic_ai/blob/main/packages/dartantic_ai/example/bin/agent.dart)

## Next Steps

- [Tool Calling](/tool-calling) - Stream with tools
- [Usage Tracking](/usage-tracking) - Monitor streaming costs
