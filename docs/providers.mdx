---
title: Providers
description: "Providers for chat and embeddings models."
---

Out of the box support for 8 built-in providers, with more available via the
`openai_compat.dart` example.

## Provider Capabilities

| Provider | Default Model | Default Embedding Model | Capabilities | Notes |
|----------|---------------|------------------------|--------------|-------|
| **OpenAI** | `gpt-4o` | `text-embedding-3-small` | Chat, Embeddings, Vision, Tools, Streaming | Full feature support |
| **OpenAI Responses** | `gpt-5` | `text-embedding-3-small` | Chat, Embeddings, Vision, Tools, Streaming, Thinking | Includes built-in server-side tools |
| **Anthropic** | `claude-sonnet-4-0` | - | Chat, Vision, Tools, Streaming, Thinking | Extended thinking with token budgets |
| **Google** | `gemini-2.5-flash` | `text-embedding-004` | Chat, Embeddings, Vision, Tools, Streaming, Thinking | Extended thinking with dynamic budgets |
| **Mistral** | `mistral-large-latest` | `mistral-embed` | Chat, Embeddings, Tools, Streaming | European servers |
| **Cohere** | `command-r-plus` | `embed-english-v3.0` | Chat, Embeddings, Tools, Streaming | RAG-optimized |
| **Ollama** | `llama3.2:latest` | - | Chat, Tools, Streaming | Local models only |
| **OpenRouter** | `google/gemini-2.5-flash` | - | Chat, Vision, Tools, Streaming | Multi-model gateway |

**Note**: Together AI, Google-OpenAI, and Ollama-OpenAI have been moved to the
`openai_compat.dart` example. You can still use them by registering them with
`Agent.providerFactories`.

## Provider Configuration

| Provider | Provider Prefix | Aliases | API Key | Provider Type |
|----------|----------------|---------|---------|---------------|
| **OpenAI** | `openai` | - | `OPENAI_API_KEY` | `OpenAIProvider` |
| **OpenAI Responses** | `openai-responses` | - | `OPENAI_API_KEY` | `OpenAIResponsesProvider` |
| **Anthropic** | `anthropic` | `claude` | `ANTHROPIC_API_KEY` | `AnthropicProvider` |
| **Google** | `google` | `gemini`, `googleai` | `GEMINI_API_KEY` | `GoogleProvider` |
| **Mistral** | `mistral` | - | `MISTRAL_API_KEY` | `MistralProvider` |
| **Cohere** | `cohere` | - | `COHERE_API_KEY` | `CohereProvider` |
| **Ollama** | `ollama` | - | None (local) | `OllamaProvider` |
| **OpenRouter** | `openrouter` | - | `OPENROUTER_API_KEY` | `OpenAIProvider` |

## Setup

```bash
# Set API keys
export OPENAI_API_KEY="sk-..."
export ANTHROPIC_API_KEY="sk-ant-..."
export GEMINI_API_KEY="..."
```

## Usage

```dart
// Basic
Agent('openai');

// With model
Agent('anthropic:claude-3-5-sonnet');

// Chat + embeddings
Agent('openai?chat=gpt-4o&embeddings=text-embedding-3-large');

// Extended thinking (OpenAI Responses, Anthropic, Google)
Agent('anthropic:claude-sonnet-4-5', enableThinking: true);

// Server-side tools (OpenAI Responses)
Agent('openai-responses:gpt-5');
```

## Find Providers

```dart
// All providers
Agent.allProviders

// By name (returns fresh instance)
Agent.createProvider('claude') // → anthropic provider

// For runtime capability discovery, use Provider.listModels()
final provider = Agent.createProvider('openai');
await for (final model in provider.listModels()) {
  print('${model.name}: ${model.kinds}'); // Shows chat, embeddings, media, etc.
}
```

## Custom Config

```dart
final provider = OpenAIProvider(
  apiKey: 'key',
  baseUrl: Uri.parse('https://custom.api.com/v1'),
);
Agent.forProvider(provider);
```

## Custom Headers

All providers support custom HTTP headers for enterprise scenarios like
authentication proxies, request tracing, or compliance logging:

```dart
final provider = GoogleProvider(
  apiKey: apiKey,
  headers: {
    'X-Request-ID': requestId,
    'X-Tenant-ID': tenantId,
  },
);

final agent = Agent.forProvider(provider);
```

Custom headers flow through to all API calls and can override internal headers
when needed. This works consistently across OpenAI, Google, Anthropic, Mistral,
and Ollama.

## Check Capabilities

Use `Provider.listModels()` for runtime capability discovery:

```dart
// List models and their capabilities
final provider = Agent.createProvider('openai');
await for (final model in provider.listModels()) {
  print('${model.name}: ${model.kinds}');
  // Output: gpt-4o: {chat}, text-embedding-3-small: {embeddings}
}

// Check if a specific model supports embeddings
final models = await provider.listModels().toList();
final hasEmbeddings = models.any((m) => m.kinds.contains(ModelKind.embeddings));
if (hasEmbeddings) {
  final agent = Agent('openai');
  final embed = await agent.embedQuery('test');
} else {
  print('Provider does not support embeddings');
}
```

### Model Kinds

Models are categorized by their kind via `ModelKind`:

- **`chat`** - Chat conversations
- **`embeddings`** - Vector embeddings
- **`media`** - Media generation (images, documents, etc.)

### Typed Output With Tools

The `typedOutputWithTools` capability indicates a provider can handle both
function calling and structured JSON output in the same request:

| Provider | Support | Implementation |
|----------|---------|----------------|
| OpenAI | ✅ | Native `response_format` |
| OpenAI Responses | ✅ | Native `response_format` |
| Anthropic | ✅ | `return_result` tool |
| Google | ✅ | Double agent orchestrator |
| OpenRouter | ✅ | OpenAI-compatible |
| Ollama | ❌ | Coming soon |
| Cohere | ❌ | API limitation |

*Together AI, Google-OpenAI, and Ollama-OpenAI also support typed output with tools
when registered via the `openai_compat.dart` example.*

**Anthropic's approach** uses the `return_result` tool pattern. This is a
special tool that allows the model to return a structured JSON response. This
is handled automatically by the Anthropic provider.

**Google's approach** uses a transparent two-phase workflow: Phase 1 executes
tools, Phase 2 requests structured output. This is handled automatically by the
Google provider.

## List Models

```dart
// List all models from a provider
final provider = Agent.createProvider('openai');
await for (final model in provider.listModels()) {
  final status = model.stable ? 'stable' : 'preview';
  print('${model.name}: ${model.displayName} [$status]');
}

// Example output:
// - openai:gpt-4-0613  (chat)
// - openai:gpt-4  (chat)
// - openai:gpt-3.5-turbo  (chat)
```

## Examples

- [List all provider
  models](https://github.com/csells/dartantic_ai/blob/main/packages/dartantic_ai/example/bin/provider_models.dart)
- [Multi-provider
  conversations](https://github.com/csells/dartantic_ai/blob/main/packages/dartantic_ai/example/bin/multi_provider.dart)
- [Custom
  providers](https://github.com/csells/dartantic_ai/blob/main/packages/dartantic_ai/example/bin/custom_provider.dart)
