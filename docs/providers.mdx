---
title: Providers
description: "Providers for chat and embeddings models."
---

Out of the box support for 11 providers, with more to come.

## Provider Capabilities

| Provider | Default Model | Default Embedding Model | Capabilities | Notes |
|----------|---------------|------------------------|--------------|-------|
| **OpenAI** | `gpt-4o` | `text-embedding-3-small` | Chat, Embeddings, Vision, Tools, Streaming | Full feature support |
| **OpenAI Responses** | `gpt-4o` | `text-embedding-3-small` | Chat, Embeddings, Vision, Tools, Streaming, Thinking | Includes built-in server-side tools |
| **Anthropic** | `claude-sonnet-4-0` | - | Chat, Vision, Tools, Streaming, Thinking | Extended thinking with token budgets |
| **Google** | `gemini-2.0-flash-exp` | `text-embedding-004` | Chat, Embeddings, Vision, Tools, Streaming, Thinking | Extended thinking with dynamic budgets |
| **Mistral** | `mistral-large-latest` | `mistral-embed` | Chat, Embeddings, Tools, Streaming | European servers |
| **Cohere** | `command-r-plus` | `embed-english-v3.0` | Chat, Embeddings, Tools, Streaming | RAG-optimized |
| **Ollama** | `llama3.2:latest` | - | Chat, Tools, Streaming | Local models only |
| **OpenRouter** | `openai/gpt-4o` | - | Chat, Vision, Tools, Streaming | Multi-model gateway |
| **Together AI** | `meta-llama/Meta-Llama-3.1-8B-Instruct-Turbo` | - | Chat, Tools, Streaming | Open source models |
| **Google-OpenAI** | `gemini-2.0-flash-exp` | - | Chat, Vision, Tools, Streaming | Gemini via OpenAI API |
| **Ollama-OpenAI** | `llama3.2:latest` | - | Chat, Tools, Streaming | Ollama via OpenAI API |

## Provider Configuration

| Provider | Provider Prefix | Aliases | API Key | Provider Type |
|----------|----------------|---------|---------|---------------|
| **OpenAI** | `openai` | - | `OPENAI_API_KEY` | `OpenAIProvider` |
| **OpenAI Responses** | `openai-responses` | - | `OPENAI_API_KEY` | `OpenAIResponsesProvider` |
| **Anthropic** | `anthropic` | `claude` | `ANTHROPIC_API_KEY` | `AnthropicProvider` |
| **Google** | `google` | `gemini`, `googleai` | `GEMINI_API_KEY` | `GoogleProvider` |
| **Mistral** | `mistral` | - | `MISTRAL_API_KEY` | `MistralProvider` |
| **Cohere** | `cohere` | - | `COHERE_API_KEY` | `CohereProvider` |
| **Ollama** | `ollama` | - | None (local) | `OllamaProvider` |
| **OpenRouter** | `openrouter` | - | `OPENROUTER_API_KEY` | `OpenAIProvider` |
| **Together AI** | `togetherai` | `together` | `TOGETHER_API_KEY` | `OpenAIProvider` |
| **Google-OpenAI** | `google-openai` | - | `GEMINI_API_KEY` | `OpenAIProvider` |
| **Ollama-OpenAI** | `ollama-openai` | - | None (local) | `OpenAIProvider` |

## Setup

```bash
# Set API keys
export OPENAI_API_KEY="sk-..."
export ANTHROPIC_API_KEY="sk-ant-..."
export GEMINI_API_KEY="..."
```

## Usage

```dart
// Basic
Agent('openai');

// With model
Agent('anthropic:claude-3-5-sonnet');

// Chat + embeddings
Agent('openai?chat=gpt-4o&embeddings=text-embedding-3-large');

// Extended thinking (OpenAI Responses, Anthropic, Google)
Agent('anthropic:claude-sonnet-4-5', enableThinking: true);

// Server-side tools (OpenAI Responses)
Agent('openai-responses:gpt-5');
```

## Find Providers

```dart
// All providers
Providers.all

// By capability
Providers.allWith({ProviderCaps.chatVision})

// By name
Providers.get('claude') // → anthropic
```

## Custom Config

```dart
final provider = OpenAIProvider(
  apiKey: 'key',
  baseUrl: Uri.parse('https://custom.api.com/v1'),
);
Agent.forProvider(provider);
```

## Check Capabilities

```dart
// Check what a provider supports
final agent = Agent('openrouter');
print('Capabilities: ${provider.caps}');
// Output: {chat, vision, toolCalls, streaming}

// Check specific capability
if (provider.caps.contains(ProviderCaps.embeddings)) {
  final embed = await agent.embedQuery('test');
} else {
  print('Provider does not support embeddings');
}
```

### Available Capabilities

- **`chat`** - Chat conversations
- **`embeddings`** - Vector embeddings
- **`chatVision`** - Image/file processing handled by the chat model
- **`toolCalls`** - Function calling
- **`multiToolCalls`** - Multiple tool calls
- **`streaming`** - Stream responses
- **`typedOutput`** - Structured JSON output
- **`typedOutputWithTools`** - Structured output combined with tool calls
- **`thinking`** - Provider streams reasoning metadata (OpenAI Responses, Anthropic, Google)

### Typed Output With Tools

The `typedOutputWithTools` capability indicates a provider can handle both
function calling and structured JSON output in the same request:

| Provider | Support | Implementation |
|----------|---------|----------------|
| OpenAI | ✅ | Native `response_format` |
| Anthropic | ✅ | `return_result` tool |
| Google | ✅ | Double agent orchestrator |
| Together AI | ✅ | OpenAI-compatible |
| OpenRouter | ✅ | OpenAI-compatible |
| Ollama | ❌ | Coming soon |
| Cohere | ❌ | API limitation |

**Anthropic's approach** uses the `return_result` tool pattern. This is a
special tool that allows the model to return a structured JSON response. This
is handled automatically by the Anthropic provider.

**Google's approach** uses a transparent two-phase workflow: Phase 1 executes
tools, Phase 2 requests structured output. This is handled automatically by the
Google provider.

## List Models

```dart
// List all models from a provider
final provider = Providers.openai;
await for (final model in provider.listModels()) {
  final status = model.stable ? 'stable' : 'preview';
  print('${model.name}: ${model.displayName} [$status]');
}

// Example output:
// - openai:gpt-4-0613  (chat)
// - openai:gpt-4  (chat)
// - openai:gpt-3.5-turbo  (chat)
```

## Examples

- [List all provider
  models](https://github.com/csells/dartantic_ai/blob/main/packages/dartantic_ai/example/bin/provider_models.dart)
- [Multi-provider
  conversations](https://github.com/csells/dartantic_ai/blob/main/packages/dartantic_ai/example/bin/multi_provider.dart)
- [Custom
  providers](https://github.com/csells/dartantic_ai/blob/main/packages/dartantic_ai/example/bin/custom_provider.dart)
