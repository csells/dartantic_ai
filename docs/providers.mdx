---
title: Providers
---

 Out of the box support for 12 providers, with more to come.

## Provider Capabilities

| Provider | Default Model | Default Embedding Model | Capabilities | Notes |
|----------|---------------|------------------------|--------------|-------|
| **OpenAI** | `gpt-4o` | `text-embedding-3-small` | Chat, Embeddings, Vision, Tools, Streaming | Full feature support |
| **OpenAI Responses** | `gpt-4o` | `text-embedding-3-small` | Chat, Embeddings, Vision, Tools, Streaming, Built-in Tools, Prompt Caching | Supports Thinking (metadata) |
| **Anthropic** | `claude-3-5-sonnet-20241022` | - | Chat, Vision, Tools, Streaming | No embeddings |
| **Google** | `gemini-2.0-flash` | `text-embedding-004` | Chat, Embeddings, Vision, Tools, Streaming | Native Gemini API |
| **Mistral** | `mistral-large-latest` | `mistral-embed` | Chat, Embeddings, Tools, Streaming | European servers |
| **Cohere** | `command-r-plus` | `embed-english-v3.0` | Chat, Embeddings, Tools, Streaming | RAG-optimized |
| **Ollama** | `qwen2.5:7b-instruct` | - | Chat, Tools, Streaming | Local models only |
| **OpenRouter** | `google/gemini-2.0-flash-001` | - | Chat, Vision, Tools, Streaming | Multi-model gateway |
| **Together AI** | `Qwen/Qwen2.5-VL-72B-Instruct` | - | Chat, Tools, Streaming | Open source models |
| **Lambda** | `hermes3-405b` | - | Chat, Tools, Streaming | Research models |
| **Google-OpenAI** | `gemini-2.0-flash` | - | Chat, Vision, Tools, Streaming | Gemini via OpenAI API |
| **Ollama-OpenAI** | `llama3.2` | - | Chat, Tools, Streaming | Ollama via OpenAI API |

## Provider Configuration

| Provider | Provider Prefix | Aliases | API Key | Provider Type |
|----------|----------------|---------|---------|---------------|
| **OpenAI** | `openai` | - | `OPENAI_API_KEY` | `OpenAIProvider` |
| **OpenAI Responses** | `openai-responses` | `oai-resp`, `openai-v2` | `OPENAI_API_KEY` | `OpenAIResponsesProvider` |
| **Anthropic** | `anthropic` | `claude` | `ANTHROPIC_API_KEY` | `AnthropicProvider` |
| **Google** | `google` | `gemini`, `googleai` | `GEMINI_API_KEY` | `GoogleProvider` |
| **Mistral** | `mistral` | - | `MISTRAL_API_KEY` | `MistralProvider` |
| **Cohere** | `cohere` | - | `COHERE_API_KEY` | `CohereProvider` |
| **Ollama** | `ollama` | - | None (local) | `OllamaProvider` |
| **OpenRouter** | `openrouter` | - | `OPENROUTER_API_KEY` | `OpenAIProvider` |
| **Together AI** | `togetherai` | `together` | `TOGETHER_API_KEY` | `OpenAIProvider` |
| **Lambda** | `lambda` | - | `LAMBDA_API_KEY` | `OpenAIProvider` |
| **Google-OpenAI** | `google-openai` | - | `GEMINI_API_KEY` | `OpenAIProvider` |
| **Ollama-OpenAI** | `ollama-openai` | - | None (local) | `OpenAIProvider` |

## Setup

```bash
# Set API keys
export OPENAI_API_KEY="sk-..."
export ANTHROPIC_API_KEY="sk-ant-..."
export GEMINI_API_KEY="..."
```

## Usage

```dart
// Basic
Agent('openai');

// OpenAI Responses API
Agent('openai-responses');

// With model
Agent('anthropic:claude-3-5-sonnet');

// Chat + embeddings
Agent('openai?chat=gpt-4o&embeddings=text-embedding-3-large');
```

## Find Providers

```dart
// All providers
Providers.all

// By capability
Providers.allWith({ProviderCaps.vision})

// By name
Providers.get('claude') // â†’ anthropic
```

## Custom Config

```dart
final provider = OpenAIProvider(
  apiKey: 'key',
  baseUrl: Uri.parse('https://custom.api.com/v1'),
);
Agent.forProvider(provider);
```

## Check Capabilities

```dart
// Check what a provider supports
final provider = Providers.openrouter;
print('Capabilities: ${provider.caps}');
// Output: {chat, vision, toolCalls, streaming}

// Check specific capability
if (provider.caps.contains(ProviderCaps.embeddings)) {
  final embed = await agent.embedQuery('test');
} else {
  print('Provider does not support embeddings');
}
```

### Available Capabilities

- **`chat`** - Chat conversations
- **`embeddings`** - Vector embeddings
- **`vision`** - Image/file processing
- **`toolCalls`** - Function calling
- **`multiToolCalls`** - Multiple tool calls
- **`streaming`** - Stream responses
- **`typedOutput`** - Structured output

## List Models

```dart
// List all models from a provider
final provider = Providers.openai;
await for (final model in provider.listModels()) {
  final status = model.stable ? 'stable' : 'preview';
  print('${model.name}: ${model.displayName} [$status]');
}

// Example output:
// - openai:gpt-4-0613  (chat)
// - openai:gpt-4  (chat)
// - openai:gpt-3.5-turbo  (chat)
```

## Examples

- [List all provider models](https://github.com/csells/dartantic_ai/blob/main/packages/dartantic_ai/example/bin/provider_models.dart)
- [Multi-provider conversations](https://github.com/csells/dartantic_ai/blob/main/packages/dartantic_ai/example/bin/multi_provider.dart)
- [Custom providers](https://github.com/csells/dartantic_ai/blob/main/packages/dartantic_ai/example/bin/custom_provider.dart)
