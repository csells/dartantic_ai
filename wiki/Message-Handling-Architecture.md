This document specifies how messages are structured and transformed across the Agent and Mapper layers in the dartantic_ai compatibility layer.

## Table of Contents
1. [Core Principles](#core-principles)
2. [Agent Layer Message Semantics](#agent-layer-message-semantics)
3. [Collecting Full History](#collecting-full-history)
4. [Provider-Specific Requirements](#provider-specific-requirements)
5. [Mapper Transformations](#mapper-transformations)
6. [Implementation Examples](#implementation-examples)

## Core Principles

### Clean Separation of Concerns

Message handling operates within the six-layer architecture. For details on each layer's responsibilities, see the [[Home#1-six-layer-architecture]] section in the Architecture Overview.

Key message-handling responsibilities by layer:
- **API Layer**: Maintains clean request/response semantics with alternating user/model messages
- **Orchestration Layer**: Manages message accumulation and tool result consolidation
- **Provider Implementation Layer**: Transforms messages to match provider-specific API requirements

## Agent Layer Message Semantics

The Agent layer maintains a consistent conversation structure:

```
User: Initial prompt
Model: Response with tool calls [toolCall1, toolCall2, toolCall3]
User: Tool results [result1, result2, result3]  // Single message with all results
Model: Final synthesis response
```

### Message Flow Diagram

```mermaid
sequenceDiagram
    participant User
    participant Agent
    participant Orchestrator
    participant Model
    participant Tools
    
    User->>Agent: Initial prompt
    Agent->>Orchestrator: Process message
    Orchestrator->>Model: Send conversation
    Model-->>Orchestrator: Response with tool calls
    
    alt Has Tool Calls
        Orchestrator->>Tools: Execute tools
        Tools-->>Orchestrator: Tool results
        Note over Orchestrator: Consolidate results into<br/>single user message
        Orchestrator->>Model: Send with tool results
        Model-->>Orchestrator: Final synthesis
    else No Tool Calls
        Note over Orchestrator: Direct response
    end
    
    Orchestrator-->>Agent: Complete messages
    Agent-->>User: Result with messages
    
    Note over Agent,User: Messages alternate:<br/>User → Model → User → Model
```

### Key Rules

1. **Request/Response Pairs**: Messages always alternate between user and model
2. **Tool Result Consolidation**: All tool results from a single round are consolidated into one user message
3. **Multiple Parts**: A single message can contain multiple parts (text, tool calls, tool results)
4. **No Provider Logic**: The Agent doesn't know or care about provider-specific requirements
5. **Complete Message History**: The Agent's `send()` method returns ALL messages from the conversation, including tool interactions, regardless of whether `outputSchema` is provided
6. **Message Processing**: Messages are processed directly by the model layer

## Collecting Full History

The Agent's sendXxx methods return ChatResult objects that contain both the new text and new messages generated during that specific invocation. This design parallels how the methods work:
- Just as sendXxx returns only the NEW text generated by the model (not the entire conversation text)
- sendXxx returns only the NEW messages generated during that send (not the entire conversation history)

### History Accumulation Flow

```mermaid
flowchart TD
    A[Start Conversation] --> B[First send]
    B --> C[result1:<br/>output: 'Hi!'<br/>messages: user1, model1]
    
    C --> D[Second send with history]
    D --> E[Pass result1.messages<br/>as history]
    E --> F[result2:<br/>output: '2+2=4'<br/>messages: user2, model2]
    
    F --> G[Third send with history]
    G --> H[Pass all previous<br/>messages as history]
    H --> I[result3:<br/>output: 'Yes, good weather'<br/>messages: user3, model3]
    
    J[Full History:<br/>...result1.messages,<br/>...result2.messages,<br/>...result3.messages]
    
    C -.-> J
    F -.-> J
    I -.-> J
    
    style A fill:#f9f,stroke:#333,stroke-width:2px
    style J fill:#9f9,stroke:#333,stroke-width:2px
```

### Non-Streaming Pattern (send, sendFor)

```dart
// Initial conversation
final result1 = await agent.send('Hello');
// result1.output contains: "Hi! How can I help?"
// result1.messages contains: [user: "Hello", model: "Hi! How can I help?"]

// Continue conversation - pass previous messages as history
final result2 = await agent.send(
  'What is 2+2?', 
  history: result1.messages,
);
// result2.output contains: "2+2 equals 4"
// result2.messages contains: [user: "What is 2+2?", model: "2+2 equals 4"]

// Full conversation history
final fullHistory = [...result1.messages, ...result2.messages];
```

### Streaming Pattern (sendStream)

```dart
// Collect messages during streaming
final messages = <ChatMessage>[];
final textBuffer = StringBuffer();

await for (final chunk in agent.sendStream('Call my tools please')) {
  textBuffer.write(chunk.output);  // Accumulate text chunks
  messages.addAll(chunk.messages); // Accumulate message chunks
}

// After streaming completes:
// textBuffer.toString() contains the full text response
// messages contains all messages from this send (user prompt, tool calls, tool results, final response)
```

### Key Principles

1. **Incremental Results**: Each ChatResult contains only NEW content from that specific send
2. **Manual History Management**: Applications must maintain conversation history by accumulating messages
3. **Consistent Pattern**: Both streaming and non-streaming follow the same incremental pattern
4. **Tool Messages Included**: When tools are called, all intermediate messages (tool calls and results) are included in the returned messages

### Example: Multi-Turn Conversation with Tools

```dart
final agent = Agent('openai:gpt-4o', tools: [weatherTool, timeTool]);
final conversationHistory = <ChatMessage>[];

// Turn 1: Simple question
final result1 = await agent.send('Hello!');
conversationHistory.addAll(result1.messages);
// History now: [user: "Hello!", model: "Hi! How can I help?"]

// Turn 2: Tool calling
final result2 = await agent.send(
  'What is the weather and time in NYC?',
  history: conversationHistory,
);
conversationHistory.addAll(result2.messages);
// result2.messages contains:
// - user: "What is the weather and time in NYC?"
// - model: [tool calls for weather and time]
// - user: [tool results]
// - model: "It's 72°F and 3:45 PM in NYC"

// Turn 3: Follow-up
final result3 = await agent.send(
  'Is that good weather for a walk?',
  history: conversationHistory,
);
conversationHistory.addAll(result3.messages);
// Full conversation maintained with proper context
```

## Typed Output Support

For typed output (structured JSON responses), see [[Typed-Output-Architecture]]. The key points for message handling:

- When `outputSchema` is provided, Agent adds a `return_result` tool
- Tool results are still consolidated into single user messages as normal
- The final JSON output replaces the text output in ChatResult

## Thinking Metadata

Some providers (starting with OpenAI Responses) can stream model "thinking" or
reasoning traces. dartantic exposes these traces via a single, provider-agnostic
metadata key:

- Key: `thinking`
- Streaming: When available, incremental thinking deltas are attached to
  `ChatResult.metadata['thinking']` on streaming chunks. These chunks do not add
  any extra message parts; the thinking text is metadata-only.
- Completion: Thinking is not re-emitted at completion (no final consolidation
  is guaranteed). The final `ChatResult` may carry only usage/finish state.
- History: Thinking is not added as visible content parts and is never sent
  back to providers. However, for each assistant message, all thinking deltas
  for that turn are consolidated and attached to the associated
  `ChatMessage.metadata['thinking']`. This keeps message alternation intact
  without polluting provider-facing history.

UX tip: If you display thinking and visible text together, insert a visual
separator when transitioning from thinking to the first visible text chunk (for
example, two newlines). This keeps the streamed reasoning visually distinct
without polluting message history.

Applications can use this metadata to show background reasoning without
polluting prompts or context. If a provider does not support thinking, the
`thinking` key will be absent.

## Streaming Enhancements

### Tool Call Argument Parsing

Tool arguments are always provided as parsed Map<String, dynamic> in ToolPart:

```dart
// Simple argument extraction - ToolPart always has parsed arguments
final args = toolPart.arguments ?? {};
// Arguments are already parsed by the provider mappers
```

### UX Enhancement: Message Separation

When streaming responses that involve tool calls, the Agent adds a newline prefix to prevent consecutive AI messages from running together:

```dart
// Prevents: "...calling tools.The weather is..."
// Becomes: "...calling tools.\nThe weather is..."
```

This only applies to the FIRST chunk of a new AI message after tool execution, maintaining proper text flow within each message.

## Provider-Specific Requirements

Different providers have different API requirements:

### Provider Message Format Comparison

```mermaid
graph TD
    subgraph "Agent Layer (Unified)"
        A[Single User Message<br/>with Multiple Tool Results]
        A --> A1[ToolPart.result 1]
        A --> A2[ToolPart.result 2]
        A --> A3[ToolPart.result 3]
    end
    
    subgraph "Provider Mappers Transform"
        B[OpenAI Mapper]
        C[Anthropic Mapper]
        D[Google Mapper]
    end
    
    subgraph "OpenAI Format"
        B1[tool message 1]
        B2[tool message 2]
        B3[tool message 3]
    end
    
    subgraph "Anthropic Format"
        C1[Single user message<br/>with content blocks]
        C1 --> C2[tool_result 1]
        C1 --> C3[tool_result 2]
        C1 --> C4[tool_result 3]
    end
    
    subgraph "Google Format"
        D1[Single message<br/>with function responses]
        D1 --> D2[function_response 1]
        D1 --> D3[function_response 2]
        D1 --> D4[function_response 3]
    end
    
    A --> B
    A --> C
    A --> D
    
    B --> B1
    B --> B2
    B --> B3
    
    C --> C1
    
    D --> D1
    
    style A fill:#f9f,stroke:#333,stroke-width:2px
    style B fill:#bbf,stroke:#333,stroke-width:2px
    style C fill:#bfb,stroke:#333,stroke-width:2px
    style D fill:#fbf,stroke:#333,stroke-width:2px
```

### OpenAI Chat Completions
- **Requirement**: Each tool result must be a separate message
- **Format**: Multiple consecutive user messages, each with role="tool"
- **Example**:
  ```
  {"role": "assistant", "tool_calls": [{"id": "1", ...}, {"id": "2", ...}]}
  {"role": "tool", "tool_call_id": "1", "content": "result1"}
  {"role": "tool", "tool_call_id": "2", "content": "result2"}
  ```

### OpenAI Responses
- **Requirement**: Two-request workflow with response linking
- **Format**: `function_call_output` format with `previous_response_id`
- **Workflow**:
  1. First request: User → Model (generates tool calls, captures response ID)
  2. Second request: Tool results → Model (uses `previous_response_id`)
- **Example**:
  ```
  // First request response metadata: {response_id: "resp_abc123..."}
  // Second request input:
  {"previous_response_id": "resp_abc123...", 
   "input": [{"type": "function_call_output", "call_id": "1", "output": "result1"}]}
  ```

### Anthropic
- **Requirement**: Tool results can be in a single user message
- **Format**: One user message with multiple tool_result blocks
- **Example**:
  ```
  {"role": "assistant", "content": [{"type": "tool_use", "id": "1"}, {"type": "tool_use", "id": "2"}]}
  {"role": "user", "content": [{"type": "tool_result", "tool_use_id": "1"}, {"type": "tool_result", "tool_use_id": "2"}]}
  ```

### Google/Gemini
- **Requirement**: Function responses in a single message
- **Format**: One message with multiple function response parts

### Ollama
- **Requirement**: Varies by endpoint (native vs OpenAI-compatible)
- **Format**: Adapts based on endpoint type

## Mapper Transformations

Each mapper transforms the Agent's message structure to match provider requirements:

### OpenAI Mapper

```dart
// Agent sends: One user message with multiple tool results
ChatMessage(
  role: ChatMessageRole.user,
  parts: [
    ToolPart.result(id: "1", name: "tool1", result: "..."),
    ToolPart.result(id: "2", name: "tool2", result: "..."),
  ]
)

// Mapper transforms to: Multiple tool messages
[
  ChatCompletionMessage.tool(toolCallId: "1", content: "..."),
  ChatCompletionMessage.tool(toolCallId: "2", content: "..."),
]
```

### Anthropic Mapper

```dart
// Agent sends: One user message with multiple tool results
ChatMessage(
  role: ChatMessageRole.user,
  parts: [
    ToolPart.result(id: "1", name: "tool1", result: "..."),
    ToolPart.result(id: "2", name: "tool2", result: "..."),
  ]
)

// Mapper transforms to: Single user message with multiple content blocks
Message(
  role: ChatMessageRole.user,
  content: [
    ContentBlock.toolResult(toolUseId: "1", content: "..."),
    ContentBlock.toolResult(toolUseId: "2", content: "..."),
  ]
)
```

## Implementation Examples

### API Layer (Agent) - Orchestrator Delegation

The Agent now supports both chat and embeddings operations:

```dart
// Agent delegates to orchestrator for complex chat workflows
final orchestrator = _selectOrchestrator(outputSchema: outputSchema, tools: model.tools);
final state = StreamingState(
  conversationHistory: conversationHistory,
  toolMap: {for (final tool in model.tools ?? <Tool>[]) tool.name: tool},
);

orchestrator.initialize(state);

try {
  await for (final result in orchestrator.processIteration(model, state)) {
    // Yield streaming results from orchestrator
    yield ChatResult<String>(
      id: result.id,
      output: result.output,
      messages: result.messages,
      finishReason: result.finishReason,
      metadata: result.metadata,
      usage: result.usage,
    );
  }
} finally {
  orchestrator.finalize(state);
}

// Agent also supports embeddings operations
final embedding = await agent.embedQuery('search text');
final embeddings = await agent.embedDocuments(['doc1', 'doc2']);
```

### Orchestration Layer - Tool Execution

```dart
// In StreamingOrchestrator.processIteration()
final toolCalls = consolidatedMessage.parts
    .whereType<ToolPart>()
    .where((p) => p.kind == ToolPartKind.call)
    .toList();

if (toolCalls.isNotEmpty) {
  // Delegate to ToolExecutor
  final results = await state.executor.executeBatch(toolCalls, state.toolMap);
  
  // Convert to ToolPart.result
  final toolResultParts = results.map((result) => ToolPart.result(
    id: result.toolCall.id,
    name: result.toolCall.name,
    result: result.isSuccess ? result.result : json.encode({'error': result.error}),
  )).toList();

  // Create single user message with all tool results
  final toolResultMessage = ChatMessage(
    role: ChatMessageRole.user,
    parts: toolResultParts,
  );

  // Add to conversation state and yield
  state.conversationHistory.add(toolResultMessage);
  yield StreamingIterationResult(
    output: '',
    messages: [toolResultMessage],
    shouldContinue: true,
  );
}
```

### OpenAI Mapper (Provider-Specific)

```dart
// In _mapMessages, when processing user messages with tool results:
if (toolResults.length > 1) {
  // OpenAI requires separate tool messages for each result
  for (final toolResult in toolResults) {
    final content = ToolResultHelpers.serialize(toolResult.result);
    expandedMessages.add(
      ChatCompletionMessage.tool(
        toolCallId: toolResult.id,
        content: content,
      ),
    );
  }
} else if (toolResults.length == 1) {
  // Single tool result
  expandedMessages.add(
    ChatCompletionMessage.tool(
      toolCallId: toolResults.first.id,
      content: ToolResultHelpers.serialize(toolResults.first.result),
    ),
  );
}
```

## Key Design Benefits

1. **Clean Architecture**: Agent maintains simple, consistent message structure while delegating complexity
2. **Orchestration Power**: Complex workflows handled by specialized orchestrators
3. **State Encapsulation**: Mutable state isolated in StreamingState for better reliability
4. **Clean Abstractions**: MessageAccumulator and ToolExecutor provide consistent interfaces
5. **Provider Flexibility**: Each mapper handles its provider's specific requirements
6. **Easy Testing**: Each layer can be tested in isolation with clear boundaries
7. **Future Proof**: New orchestrators and providers can be added without changing core logic
8. **Resource Management**: Guaranteed cleanup through try/finally patterns
9. **Clear Semantics**: Request/response pairs maintained with orchestrated execution

## Orchestration Layer Benefits

### Message Flow Control

1. **Streaming Coordination**: Orchestrators manage complex streaming workflows
2. **State Transitions**: Clean state management through StreamingState
3. **Tool Orchestration**: Centralized tool execution with error handling
4. **UX Enhancement**: Consistent streaming experience across providers

### Component Interactions

```dart
// Clear data flow through orchestration layer
Agent → StreamingOrchestrator → ChatModel → Provider API
  ↓           ↓                    ↓
StreamingState → ToolExecutor → MessageAccumulator
```
